{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e96ba-1b6b-403b-94b7-8b5fbc112c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install pinecone-client==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5dd7a8-e83a-4964-9c40-1e74cca7726d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.chains import ConversationChain, HypotheticalDocumentEmbedder, LLMChain\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.chat_models import ChatMlflow\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "from domino_data.vectordb import DominoPineconeConfiguration\n",
    "\n",
    "from ragatouille import RAGPretrainedModel\n",
    "\n",
    "import os\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c38b1-47e2-451b-9e39-ffde7db7cfab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the embedding model\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "embedding_model_name = \"BAAI/bge-small-en\"\n",
    "os.environ['SENTENCE_TRANSFORMERS_HOME'] = '/mnt/code/model_cache/'\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=embedding_model_name,\n",
    "                                      model_kwargs=model_kwargs,\n",
    "                                      encode_kwargs=encode_kwargs\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d845c-bb8c-4ec6-b3de-61c0f8768bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Pinecone index\n",
    "datasource_name = \"Rakuten\"\n",
    "conf = DominoPineconeConfiguration(datasource=datasource_name)\n",
    "api_key = os.environ.get(\"DOMINO_VECTOR_DB_METADATA\", datasource_name)\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=api_key,\n",
    "    environment=\"domino\",\n",
    "    openapi_config=conf\n",
    ")\n",
    "\n",
    "index = pinecone.Index(\"rakuten\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c2b3e-ee1c-48be-817f-e736e4fe2ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = ChatMlflow(\n",
    "    target_uri=os.environ[\"DOMINO_MLFLOW_DEPLOYMENTS\"],\n",
    "    endpoint=\"chat-gpt35turbo-sm\",\n",
    ")\n",
    "\n",
    "conversation_openai = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationSummaryMemory(llm=chat),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "conversation_anthropic = ConversationChain(\n",
    "        llm=ChatAnthropic(model='claude-2.1'),\n",
    "        memory=ConversationSummaryMemory(llm=ChatAnthropic(model='claude-2.1')),\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"assistant\", \"content\": \"How can I help you today?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061e75f-b198-43d9-916b-32cf0231edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup HyDE\n",
    "\n",
    "hyde_prompt_template = \"\"\"You are a virtual assistant for Rakuten and your task is to answer questions related to Rakuten which includes general information about Rakuten\n",
    "\"Please answer the user's question below \\n \n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "hyde_prompt = PromptTemplate(input_variables=[\"question\"], template=hyde_prompt_template)\n",
    "hyde_llm_chain = LLMChain(llm=chat, prompt=hyde_prompt)\n",
    "\n",
    "hyde_embeddings = HypotheticalDocumentEmbedder(\n",
    "    llm_chain=hyde_llm_chain, base_embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f8710-fc11-4444-9f8c-235141299e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get relevant docs through vector DB\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.5\n",
    "\n",
    "# Number of texts to match (may be less if no suitable match)\n",
    "NUM_TEXT_MATCHES = 5\n",
    "\n",
    "# Number of texts to return from reranking\n",
    "NUM_RERANKING_MATCHES = 3\n",
    "\n",
    "# Create prompt\n",
    "template = \"\"\" You are a virtual assistant for Rakuten and your task is to answer questions related to Rakuten which includes general information about Rakuten.\n",
    "\n",
    "                Respond in the style of a polite helpful assistant and do not allude that you have looked up the context.\n",
    "\n",
    "                Do not hallucinate. If you don't find an answer, you can point user to the official website here: https://www.rakuten.com/help . \n",
    "\n",
    "                In your response, include the following url links at the end of your response {url_links} and any other relevant URL links that you refered.\n",
    "\n",
    "                Also, at the end of your response, ask if your response was helpful\". \n",
    "\n",
    "                Here is some relevant context: {context}\"\"\"\n",
    "\n",
    "# Load the reranking model\n",
    "colbert = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "\n",
    "# Get relevant docs through vector DB\n",
    "def get_relevant_docs(user_input, num_matches=NUM_TEXT_MATCHES, use_hyde=True):\n",
    "   \n",
    "    if use_hyde:\n",
    "        embedded_query = hyde_embeddings.embed_query(user_input)\n",
    "    else:\n",
    "        embedded_query = embeddings.embed_query(user_input)\n",
    "    \n",
    "    relevant_docs = index.query(\n",
    "        vector=embedded_query,\n",
    "        top_k=num_matches,\n",
    "        include_values=True,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    matches = relevant_docs[\"matches\"]\n",
    "    filtered_matches = [match for match in matches if match['score'] >= SIMILARITY_THRESHOLD]\n",
    "    relevant_docs[\"matches\"] = filtered_matches\n",
    "\n",
    "    return relevant_docs\n",
    "\n",
    " \n",
    "def build_system_prompt(user_input, rerank=True, use_hyde=True):\n",
    "    \n",
    "    relevant_docs = get_relevant_docs(user_input)\n",
    "    \n",
    "    actual_num_matches = len(relevant_docs[\"matches\"])\n",
    "    urls = set([relevant_docs[\"matches\"][i][\"metadata\"][\"source\"] for i in range(actual_num_matches)])\n",
    "    contexts = [relevant_docs[\"matches\"][i][\"metadata\"][\"text\"] for i in range(actual_num_matches)]\n",
    "    \n",
    "    if rerank and actual_num_matches >= NUM_RERANKING_MATCHES:\n",
    "        docs = colbert.rerank(query=user_question, documents=contexts, k=NUM_RERANKING_MATCHES)\n",
    "        result_indices = [docs[i][\"result_index\"] for i in range(NUM_RERANKING_MATCHES)]\n",
    "        contexts = [contexts[index] for index in result_indices]\n",
    "        urls = [list(urls)[index] for index in result_indices]\n",
    "    \n",
    "    # TODO : pull the prompt template from the Hub\n",
    "    \n",
    "    # Create prompt\n",
    "    template = \"\"\" You are a virtual assistant for Rakuten and your task is to answer questions related to Rakuten which includes general information about Rakuten.\n",
    "\n",
    "                Respond in the style of a polite helpful assistant and do not allude that you have looked up the context.\n",
    "\n",
    "                Do not hallucinate. If you don't find an answer, you can point user to the official website here: https://www.rakuten.com/help . \n",
    "\n",
    "                In your response, include the following url links at the end of your response {url_links} and any other relevant URL links that you refered.\n",
    "\n",
    "                Also, at the end of your response, ask if your response was helpful\". \n",
    "\n",
    "                Here is some relevant context: {context}\"\"\"\n",
    " \n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"url_links\", \"context\"],\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "    system_prompt = prompt_template.format( url_links=urls, context=contexts)\n",
    " \n",
    "    return system_prompt\n",
    " \n",
    "# Query the Open AI Model\n",
    "def queryAIModel(user_input, llm_name=\"openai\", use_hyde=True):\n",
    "\n",
    "    system_prompt = build_system_prompt(user_input)            \n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=system_prompt\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=user_input\n",
    "        ),\n",
    "    ]\n",
    "    if llm_name.lower() == \"openai\":\n",
    "        output = conversation_openai.predict(input=messages)\n",
    "    else:\n",
    "        output = conversation_anthropic.predict(input=messages)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888553e6-6979-495d-b3e2-3d4c4a8c75a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_question = \"text: Google API Disclosure Rakuten uses Google APIs when you use Google to sign in to your Rakuten account. Our use of information from the Google APIs will be in compliance with the Google API Services User Data Policy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854478ef-aaf8-41a7-b460-9cbdb6ff2ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ask a question ; uncomment to test\n",
    "user_question = input(\"Please provide your question here :\")\n",
    "result = queryAIModel(user_question)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe57134-b2b2-4e7a-9110-356f9a2f7650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
